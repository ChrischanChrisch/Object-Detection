{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Aufteilen der Datensätze in Test und Train\n",
    "Alle Bilder und xml-Datein sollten im Ordner C:\\Tensorflow2\\workspace\\training_demo\\images   abgelegt sein\n",
    "ebenso sollte unterordner 'test' und 'train' angelegt sein.  \n",
    "\n",
    "Die Aufteilung kann in Zeile 10 ratio = 0.1 angepasst werden.\n",
    "Hier werden 10% der Daten in den Test Ordner gepackt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from shutil import copyfile\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "imageDir = r'C:\\Tensorflow2\\workspace\\Training_demo\\images'\n",
    "outputDir = r'C:\\Tensorflow2\\workspace\\Training_demo\\images'\n",
    "ratio = 0.1\n",
    "xml = True\n",
    "\n",
    "def iterate_dir(source, dest, ratio, copy_xml):\n",
    "    source = source.replace('\\\\', '/')\n",
    "    dest = dest.replace('\\\\', '/')\n",
    "    train_dir = os.path.join(dest, 'train')\n",
    "    test_dir = os.path.join(dest, 'test')\n",
    "\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir)\n",
    "    if not os.path.exists(test_dir):\n",
    "        os.makedirs(test_dir)\n",
    "\n",
    "    images = [f for f in os.listdir(source)\n",
    "              if re.search(r'([a-zA-Z0-9\\s_\\\\.\\-\\(\\):])+(.jpg|.jpeg|.png)$', f)]\n",
    "\n",
    "    num_images = len(images)\n",
    "    num_test_images = math.ceil(ratio*num_images)\n",
    "\n",
    "    for i in range(num_test_images):\n",
    "        idx = random.randint(0, len(images)-1)\n",
    "        filename = images[idx]\n",
    "        copyfile(os.path.join(source, filename),\n",
    "                 os.path.join(test_dir, filename))\n",
    "        if copy_xml:\n",
    "            xml_filename = os.path.splitext(filename)[0]+'.xml'\n",
    "            copyfile(os.path.join(source, xml_filename),\n",
    "                     os.path.join(test_dir,xml_filename))\n",
    "        images.remove(images[idx])\n",
    "\n",
    "    for filename in images:\n",
    "        copyfile(os.path.join(source, filename),\n",
    "                 os.path.join(train_dir, filename))\n",
    "        if copy_xml:\n",
    "            xml_filename = os.path.splitext(filename)[0]+'.xml'\n",
    "            copyfile(os.path.join(source, xml_filename),\n",
    "                     os.path.join(train_dir, xml_filename))\n",
    "\n",
    "\n",
    "def main():   \n",
    "\n",
    "    # Now we are ready to start the iteration\n",
    "    start_time = time.perf_counter()\n",
    "    print('Start')\n",
    "    iterate_dir(imageDir, outputDir, ratio, xml)\n",
    "    end_time = time.perf_counter() - start_time\n",
    "    print('Ende: Dauer = ', end_time)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1b. Andere Label verwenden (optional)\n",
    "neue xml-Datein zu den bereits aufgeteilten Bildern zuordnen\n",
    "dazu die neuen xml-Dateien C:\\Tensorflow2\\workspace\\training_demo\\images  ablegen\n",
    "unötig zu sagen dass die xml-Dateien den gleichen Namen haben wie das dazugehörige Bild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test_Train_xml.py\n",
    "# wird nur benötigt wenn Labels geändert wurden und neue XML-Datein zu den bereits aufgeteileten \n",
    "# Bilder zugordenet werden sollen \n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "imageDir = r'C:\\Tensorflow2\\workspace\\Training_demo\\images'\n",
    "#CWD_Path = os.getcwd()\n",
    "start_time = time.perf_counter()\n",
    "print('Start:')\n",
    "for Folder in ['Test','Train']:\n",
    "    print(Folder)\n",
    "    for img in glob.glob(os.path.join(imageDir,Folder,'*.jpg')):\n",
    "        img_path = os.path.split(img)\n",
    "        img_path_2 = img_path[1].split('.')\n",
    "\n",
    "        for xml_file in glob.glob(CWD_Path + '\\*.xml'):\n",
    "            xml_path = os.path.split(xml_file)\n",
    "            xml_path_2 = xml_path[1].split('.')\n",
    "\n",
    "            if img_path_2 [0] == xml_path_2[0]:\n",
    "                print(img_path[1])\n",
    "                print(xml_path[1])\n",
    "                os.replace(xml_file, os.path.join(CWD_Path,Folder,xml_path[1]))\n",
    "                \n",
    "end_time = time.perf_counter() - start_time\n",
    "print('Ende: Dauer = ', end_time)\n",
    "print('Daten wurden aufgeteilt.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Label_Map erstellen\n",
    "die Namen der Labels müssen angepasst werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = [{'name':'Label1', 'id':1},\n",
    "          {'name':'Label2', 'id':2},\n",
    "          {'name':'Labelx', 'id':3}]\n",
    "\n",
    "with open(r'C:\\Tensorflow2\\workspace\\Training_demo\\annotations\\label_map.pbtxt', 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')\n",
    "print('label_map.pbtxt wurde erstellt.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3a. Umwandeln der csv in tfrecord\n",
    "# Test\n",
    "erstellt eine csv und eine .tfrecord Datei für Test\n",
    "Achtung!! es muss eine label_map.pbtxt vorhanden sein unter C:\\Tensorflow2\\workspace\\training_demo\\annotations\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import io\n",
    "import xml.etree.ElementTree as ET\n",
    "import sys\n",
    "sys.path.append('C:\\Tensorflow2\\models-master\\research')\n",
    "sys.path.append('C:\\Tensorflow2\\models-master\\research\\object_detection')\n",
    "#import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "import tensorflow.compat.v1 as tf\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util, label_map_util\n",
    "from collections import namedtuple\n",
    "import time\n",
    "\n",
    "xml_dir = r'C:\\Tensorflow2\\workspace\\Training_demo\\images\\test'\n",
    "labels_path = r'C:\\Tensorflow2\\workspace\\Training_demo\\annotations\\label_map.pbtxt'\n",
    "output_path = r'C:\\Tensorflow2\\workspace\\Training_demo\\annotations\\test.record'\n",
    "image_dir = xml_dir\n",
    "csv_path = r'C:\\Tensorflow2\\workspace\\Training_demo\\images\\_Test_labels.csv'\n",
    "\n",
    "label_map = label_map_util.load_labelmap(labels_path)\n",
    "label_map_dict = label_map_util.get_label_map_dict(label_map)\n",
    "\n",
    "\n",
    "def xml_to_csv(path): \n",
    "    xml_list = []\n",
    "    for xml_file in glob.glob(path + '/*.xml'):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        for member in root.findall('object'):\n",
    "            value = (root.find('filename').text,\n",
    "                     int(root.find('size')[0].text),\n",
    "                     int(root.find('size')[1].text),\n",
    "                     member[0].text,\n",
    "                     int(member[4][0].text),\n",
    "                     int(member[4][1].text),\n",
    "                     int(member[4][2].text),\n",
    "                     int(member[4][3].text)\n",
    "                     )\n",
    "            xml_list.append(value)\n",
    "    column_name = ['filename', 'width', 'height',\n",
    "                   'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
    "    return xml_df\n",
    "\n",
    "\n",
    "def class_text_to_int(row_label):\n",
    "    return label_map_dict[row_label]\n",
    "\n",
    "\n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "\n",
    "def create_tf_example(group, path):\n",
    "    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(class_text_to_int(row['class']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    start_time = time.perf_counter()\n",
    "    print('Start:')\n",
    "    writer = tf.python_io.TFRecordWriter(output_path)\n",
    "    path = os.path.join(image_dir)\n",
    "    examples = xml_to_csv(xml_dir)\n",
    "    grouped = split(examples, 'filename')\n",
    "    for group in grouped:\n",
    "        #print(group['filename'])\n",
    "        tf_example = create_tf_example(group, path)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "    print('Successfully created the TFRecord file: {}'.format(output_path))\n",
    "    if csv_path is not None:\n",
    "        examples.to_csv(csv_path, index=None)\n",
    "        print('Successfully created the CSV file: {}'.format(csv_path))\n",
    "        \n",
    "    end_time = time.perf_counter() - start_time\n",
    "    print('Ende: Dauer = ', end_time)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3b. Umwandeln der csv in tfrecord\n",
    "# Train\n",
    "erstellt eine csv und eine .tfrecord Datei für Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import io\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "import tensorflow.compat.v1 as tf\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util, label_map_util\n",
    "from collections import namedtuple\n",
    "\n",
    "xml_dir = r'C:\\Tensorflow2\\workspace\\Training_demo\\images\\train'\n",
    "labels_path = r'C:\\Tensorflow2\\workspace\\Training_demo\\annotations\\label_map.pbtxt'\n",
    "output_path = r'C:\\Tensorflow2\\workspace\\Training_demo\\annotations\\train.record'\n",
    "image_dir = xml_dir\n",
    "csv_path = r'C:\\Tensorflow2\\workspace\\Training_demo\\images\\_Train_labels.csv'\n",
    "\n",
    "label_map = label_map_util.load_labelmap(labels_path)\n",
    "label_map_dict = label_map_util.get_label_map_dict(label_map)\n",
    "\n",
    "\n",
    "def xml_to_csv(path): \n",
    "    xml_list = []\n",
    "    for xml_file in glob.glob(path + '/*.xml'):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        for member in root.findall('object'):\n",
    "            value = (root.find('filename').text,\n",
    "                     int(root.find('size')[0].text),\n",
    "                     int(root.find('size')[1].text),\n",
    "                     member[0].text,\n",
    "                     int(member[4][0].text),\n",
    "                     int(member[4][1].text),\n",
    "                     int(member[4][2].text),\n",
    "                     int(member[4][3].text)\n",
    "                     )\n",
    "            xml_list.append(value)\n",
    "    column_name = ['filename', 'width', 'height',\n",
    "                   'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
    "    return xml_df\n",
    "\n",
    "\n",
    "def class_text_to_int(row_label):\n",
    "    return label_map_dict[row_label]\n",
    "\n",
    "\n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "\n",
    "def create_tf_example(group, path):\n",
    "    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(class_text_to_int(row['class']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    start_time = time.perf_counter()\n",
    "    print('Start:')\n",
    "    writer = tf.python_io.TFRecordWriter(output_path)\n",
    "    path = os.path.join(image_dir)\n",
    "    examples = xml_to_csv(xml_dir)\n",
    "    grouped = split(examples, 'filename')\n",
    "    for group in grouped:\n",
    "        #print(group['filename'])\n",
    "        tf_example = create_tf_example(group, path)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "    print('Successfully created the TFRecord file: {}'.format(output_path))\n",
    "    if csv_path is not None:\n",
    "        examples.to_csv(csv_path, index=None)\n",
    "        print('Successfully created the CSV file: {}'.format(csv_path))\n",
    "        \n",
    "    end_time = time.perf_counter() - start_time\n",
    "    print('Ende: Dauer = ', end_time)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. pipeline config anpassen\n",
    "dazu die piplien.config vom pretrained model kopieren in \n",
    "und Anpassungen bei folgenden Punkten vornehmen:\n",
    "Zeile 3:  PRETRAINED_MODEL_NAME - anpassen \n",
    "\n",
    "vorher muss ein pretrained Model von https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md runtergelade und in C:/Tensorflow2/workspace/training_demo/pretrained_Models gespeichert werden. \n",
    "In diesem Bsp. wird \n",
    "faster_rcnn_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8 \n",
    "genutzt.\n",
    "\n",
    "Achtung im Unterschritt 3 Zeile 1 muss mindestens \n",
    "pipeline_config.model.faster_rcnn.num_classes = xx\n",
    "angepasst werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_path = r'C:\\Tensorflow2\\workspace\\Training_demo'\n",
    "PRETRAINED_MODEL_NAME = 'faster_rcnn_resnet50_v1_1024x1024_coco17_tpu-8'\n",
    "!copy {os.path.join(root_path,'pretrained-models', PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(os.path.join(root_path, 'models\\my_model'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n",
    "config_path = os.path.join(root_path, 'models\\my_model\\pipeline.config')\n",
    "config = config_util.get_configs_from_pipeline_file(config_path)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(config_path, \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.faster_rcnn.num_classes = 11\n",
    "pipeline_config.train_config.batch_size = 1\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(root_path,'pretrained-models', PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\" \n",
    "pipeline_config.train_input_reader.label_map_path = os.path.join(root_path,'annotations', 'label_map.pbtxt')\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(root_path,'annotations', 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = os.path.join(root_path,'annotations', 'label_map.pbtxt')\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(root_path,'annotations', 'test.record')]\n",
    "#pipeline_config.train_config.data_augmentation_options ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(config_path, \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Das Training\n",
    "individuell angepasst werden kann Zeile 11 \n",
    "Zeile 20  num_train_steps  ist anzupassen, wenn nach bestimmten Schritte eine evaluierung (Schritt 4a) durchgeführt werden soll.\n",
    "\n",
    "vorher muss ein pretrained Model von https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md runtergelade und in C:/Tensorflow2/workspace/training_demo/prtrained_Models  gespeichert werden.\n",
    "In diesem Bsp. faster_rcnn_resnet50_v1_1024x1024_coco17_tpu-8   genutzt.\n",
    "\n",
    "Von da die entsprechende config -Datei  nehmen und in C:/Tensorflow2/workspace/training_demo/models/my_model...   speichern\n",
    "in der verschobenen config-Datei müssen die Zeilen \n",
    "110 - fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
    "143 - label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\n",
    "145 - input_path: \"PATH_TO_BE_CONFIGURED/train2017-?????-of-00256.tfrecord\"\n",
    "156 - label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\n",
    "160 - input_path: \"PATH_TO_BE_CONFIGURED/val2017-?????-of-00032.tfrecord\"\n",
    "angepast werden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_main_tf2.py\n",
    "# individuell angepasst werden müssen die Zeilen 23, 24\n",
    "\n",
    "#from absl import flags\n",
    "import os\n",
    "import tensorflow.compat.v2 as tf\n",
    "from object_detection import model_lib_v2\n",
    "import time\n",
    "\n",
    "Path_to_scripts = r'C:\\Tensorflow2\\workspace\\Training_demo'\n",
    "model_dir = os.path.join(Path_to_scripts, 'models\\my_model')\n",
    "pipeline_config_path = os.path.join(model_dir, 'pipeline.config')\n",
    "num_train_steps = None\n",
    "eval_on_train_data = False\n",
    "sample_1_of_n_eval_examples = None\n",
    "sample_1_of_n_eval_on_train_examples = 5\n",
    "checkpoint_dir = None\n",
    "eval_timeout = 3600\n",
    "use_tpu = False\n",
    "num_train_steps = 2000\n",
    "num_workers = 1\n",
    "checkpoint_every_n = 1000\n",
    "record_summaries = True\n",
    "\n",
    "def main(_):  \n",
    "\n",
    "  if checkpoint_dir:\n",
    "    model_lib_v2.eval_continuously(\n",
    "        pipeline_config_path=pipeline_config_path,\n",
    "        model_dir=model_dir,\n",
    "        train_steps=num_train_steps,\n",
    "        sample_1_of_n_eval_examples=sample_1_of_n_eval_examples,\n",
    "        sample_1_of_n_eval_on_train_examples=(\n",
    "            sample_1_of_n_eval_on_train_examples),\n",
    "        checkpoint_dir=checkpoint_dir,\n",
    "        wait_interval=300, timeout=eval_timeout)\n",
    "  else:\n",
    "    if use_tpu:\n",
    "      # TPU is automatically inferred if tpu_name is None and\n",
    "      # we are running under cloud ai-platform.\n",
    "      resolver = tf.distribute.cluster_resolver.TPUClusterResolver(\n",
    "          tpu_name)\n",
    "      tf.config.experimental_connect_to_cluster(resolver)\n",
    "      tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "      strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
    "    elif num_workers > 1:\n",
    "      strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "    else:\n",
    "      strategy = tf.compat.v2.distribute.MirroredStrategy()\n",
    "\n",
    "    with strategy.scope():\n",
    "      model_lib_v2.train_loop(\n",
    "          pipeline_config_path=pipeline_config_path,\n",
    "          model_dir=model_dir,\n",
    "          train_steps=num_train_steps,\n",
    "          use_tpu=use_tpu,\n",
    "          checkpoint_every_n=checkpoint_every_n,\n",
    "          record_summaries=record_summaries)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.perf_counter()\n",
    "    #main()\n",
    "    tf.compat.v1.app.run()\n",
    "    end_time = time.perf_counter() - start_time\n",
    "    print('Training abgeschlossen: Dauer = ', end_time)\n",
    "  #tf.compat.v1.app.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5a. Evaluate the Training (optional)\n",
    "anders als beim Training ist hier ein Wert für Checkpoin_dir gesetzt.\n",
    "Zeile 21: checkpoint_dir = model_dir\n",
    "unvorteilhafter weise kann die Evaluierung nicht parallel zum Training laufen (kommt hoffentlich noch, bei TF1 gings ja auch). Also muss das Training mit num_train_steps = xxx  in kleine Portionen geteilt werden, und zwischendurch immer eval- wer es bracuht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_main_tf2.py\n",
    "# individuell angepasst werden müssen die Zeilen 23, 24\n",
    "\n",
    "#from absl import flags\n",
    "import os\n",
    "import tensorflow.compat.v2 as tf\n",
    "from object_detection import model_lib_v2\n",
    "import time\n",
    "\n",
    "Path_to_scripts = r'C:\\Tensorflow2\\workspace\\Training_demo'\n",
    "model_dir = os.path.join(Path_to_scripts, 'models\\my_model')\n",
    "pipeline_config_path = os.path.join(model_dir, 'pipeline.config')\n",
    "num_train_steps = None\n",
    "eval_on_train_data = False\n",
    "sample_1_of_n_eval_examples = None\n",
    "sample_1_of_n_eval_on_train_examples = 5\n",
    "checkpoint_dir = model_dir\n",
    "eval_timeout = 60\n",
    "use_tpu = False\n",
    "num_train_steps = None\n",
    "num_workers = 1\n",
    "checkpoint_every_n = 1000\n",
    "record_summaries = True\n",
    "\n",
    "def main(_):  \n",
    "\n",
    "  if checkpoint_dir:\n",
    "    model_lib_v2.eval_continuously(\n",
    "        pipeline_config_path=pipeline_config_path,\n",
    "        model_dir=model_dir,\n",
    "        train_steps=num_train_steps,\n",
    "        sample_1_of_n_eval_examples=sample_1_of_n_eval_examples,\n",
    "        sample_1_of_n_eval_on_train_examples=(\n",
    "            sample_1_of_n_eval_on_train_examples),\n",
    "        checkpoint_dir=checkpoint_dir,\n",
    "        wait_interval=300, timeout=eval_timeout)\n",
    "  else:\n",
    "    if use_tpu:\n",
    "      # TPU is automatically inferred if tpu_name is None and\n",
    "      # we are running under cloud ai-platform.\n",
    "      resolver = tf.distribute.cluster_resolver.TPUClusterResolver(\n",
    "          tpu_name)\n",
    "      tf.config.experimental_connect_to_cluster(resolver)\n",
    "      tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "      strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
    "    elif num_workers > 1:\n",
    "      strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "    else:\n",
    "      strategy = tf.compat.v2.distribute.MirroredStrategy()\n",
    "\n",
    "    with strategy.scope():\n",
    "      model_lib_v2.train_loop(\n",
    "          pipeline_config_path=pipeline_config_path,\n",
    "          model_dir=model_dir,\n",
    "          train_steps=num_train_steps,\n",
    "          use_tpu=use_tpu,\n",
    "          checkpoint_every_n=checkpoint_every_n,\n",
    "          record_summaries=record_summaries)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.perf_counter()\n",
    "    #main()\n",
    "    tf.compat.v1.app.run()\n",
    "    end_time = time.perf_counter() - start_time\n",
    "    print('Evaluierung abgeschlossen: Dauer = ', end_time)\n",
    "  #tf.compat.v1.app.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Ergebnisse in Tensorboard\n",
    "dazu die Commands in Anacoda-prompt  oder cmd ausführen.\n",
    "command3 - evt. muss der Ordner my_....   angepasst werden "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command1 = \"activate tf2_env\" \n",
    "command2 = \"cd C:\\Tensorflow2\\workspace\\Training_demo\"\n",
    "command3 = \"tensorboard --logdir=models/my_model\"\n",
    "print(command1)\n",
    "print(command2)\n",
    "print(command3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. export model\n",
    "im command müssen die beiden Pfad angepasst werden:\n",
    "pipelin_config_path\n",
    "trained_checkpoint_dir\n",
    "\n",
    "und die exporter_main_v2.py sollte in  C:\\Tensorflow2\\workspace\\training_demo\\  liegen\n",
    "zu finden ist sie unter: C:\\Tensorflow2\\models-master\\research\\object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = python C:\\Tensorflow2\\workspace\\Training_demo\\exporter_main_v2.py --input_type image_tensor --pipeline_config_path C:\\Tensorflow2\\workspace\\training_demo\\models\\my_model\\pipeline.config --trained_checkpoint_dir C:\\Tensorflow2\\workspace\\training_demo\\models\\my_model\\ --output_directory C:\\Tensorflow2\\workspace\\training_demo\\exported-models\\my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Run model with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# %%\n",
    "# This demo will take you through the steps of running an \"out-of-the-box\" TensorFlow 2 compatible\n",
    "# detection model on a collection of images. More specifically, in this example we will be using\n",
    "# the `Saved Model Format <https://www.tensorflow.org/guide/saved_model>`__ to load the model.\n",
    "\n",
    "# %%\n",
    "# Download the test images\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# First we will download the images that we will use throughout this tutorial. The code snippet\n",
    "# shown bellow will download the test images from the `TensorFlow Model Garden <https://github.com/tensorflow/models/tree/master/research/object_detection/test_images>`_\n",
    "# and save them inside the ``data/images`` folder.\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "#import pathlib\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "#from PIL import Image\n",
    "#import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from utils import label_map_util\n",
    "#from utils import visualization_utils as viz_utils\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
    "\n",
    "# Enable GPU dynamic memory allocation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "\n",
    "IMAGE_PATHS = r'C:\\Tensorflow2\\workspace\\training_demo\\test'\n",
    "PATH_TO_LABELS = r'C:\\Tensorflow2\\workspace\\training_demo\\annotations\\label_map.pbtxt'\n",
    "PATH_TO_MODEL_DIR = r'C:\\Tensorflow2\\workspace\\training_demo\\exported-models\\my_model'\n",
    "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
    "alpha = 0.1 #transparency factor\n",
    "prediction_score = 0.5 #treshold  for prediction\n",
    "print('Loading model...', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# Load saved model and build the detection function\n",
    "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)\n",
    "\n",
    "# Here are some simple things to try out if you are curious:\n",
    "#\n",
    "# * Modify some of the input images and see if detection still works. Some simple things to try out here (just uncomment the relevant portions of code) include flipping the image horizontally, or converting to grayscale (note that we still expect the input image to have 3 channels).\n",
    "# * Print out `detections['detection_boxes']` and try to match the box locations to the boxes in the image.  Notice that coordinates are given in normalized form (i.e., in the interval [0, 1]).\n",
    "# * Set ``min_score_thresh`` to other values (between 0 and 1) to allow more detections in or to filter out more detections.\n",
    "\n",
    "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
    "\n",
    "images = glob.glob(os.path.join(IMAGE_PATHS, '*.jpg'))\n",
    "\n",
    "for img in images:\n",
    "\n",
    "    #print('Running inference for {}... '.format(img), end='')\n",
    "\n",
    "    image = cv2.imread(img)  # (PATH_TO_IMAGE)\n",
    "    # Things to try:\n",
    "    #image = cv2.flip(image, 1)  # horizontal flip\n",
    "    #image = cv2.flip(image, 0)  # vertical flip\n",
    "\n",
    "    image_copy = cv2.resize(image, (1280, 720))\n",
    "    overlay = image_copy.copy()\n",
    "\n",
    "    image_np = np.array(image)#load_image_into_numpy_array(image_path)\n",
    "\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image_np)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    # input_tensor = np.expand_dims(image_np, 0)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                   for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    #image_np_with_detections = image_np.copy()\n",
    "\n",
    "    for i in range(0, len(detections['detection_classes'])):\n",
    "        if detections['detection_scores'][i] > prediction_score:\n",
    "            ymin, xmin, ymax, xmax = detections['detection_boxes'][i]\n",
    "            class_name = category_index[detections['detection_classes'][i]]['name']\n",
    "            xmin = int(xmin * 1280)\n",
    "            xmax = int(xmax * 1280)\n",
    "            ymin = int(ymin * 720)\n",
    "            ymax = int(ymax * 720)\n",
    "            score = round(detections['detection_scores'][i] * 100, 1)\n",
    "            print(xmin, ymin, xmax, ymax, class_name, score)\n",
    "            text = class_name + ' ' + str(score)\n",
    "            cv2.rectangle(overlay, (xmin, ymin), (xmax, ymax), [0, 0, 255], -1)\n",
    "            cv2.rectangle(image_copy, (xmin, ymin), (xmax, ymax), [255, 255, 255], 2)\n",
    "            image = cv2.putText(image_copy, text, (xmin, ymin), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2,\n",
    "                                cv2.LINE_AA)\n",
    "\n",
    "    image_copy = cv2.addWeighted(overlay, alpha, image_copy, 1 - alpha, 0)\n",
    "    cv2.imshow('result', image_copy)\n",
    "\n",
    "    # Press any key to close the image\n",
    "    k = cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_env",
   "language": "python",
   "name": "tf2_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
